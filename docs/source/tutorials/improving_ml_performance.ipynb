{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f361b775-0fb3-4f09-89b9-6672775382bb",
   "metadata": {},
   "source": [
    "# Improving ML Performance Via Data Curation with Train vs Test Splits\n",
    "\n",
    "In typical Machine Learning projects, we split our dataset into **training** data for fitting models and **test** data to evaluate model performance. For noisy real-world datasets, detecting/correcting errors in the training data is important to train robust models, but it's less recognized that the test set can also be noisy.\n",
    "For accurate model evaluation, it is vital to **find and fix issues in the test data** as well. Some evaluation metrics are particularly sensitive to outliers and noisy labels.\n",
    "This tutorial demonstrates a way to use `cleanlab` (via `Datalab`) to curate both your training and test data, ensuring **robust model training** and **reliable performance evaluation**.\n",
    "We recommend first completing some `Datalab` tutorials before diving into this more complex subject.\n",
    "\n",
    "Here's how we recommend handling noisy training and test data (this tutorial walks through these steps):\n",
    "\n",
    "1. [Preprocess](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d) your training and test data to be suitable for ML. Use cleanlab to check for issues in the merged dataset like train/test leakage or drift.\n",
    "2. Fit your ML model to your noisy training data and get its predictions/embeddings for your test data. Use these model outputs with cleanlab to detect issues in your **test** data.\n",
    "3. Manually review/correct cleanlab-detected issues in your test data. **We caution against blindly automated correction of test data**. Changes to your test set should be carefully verified to ensure they will lead to more accurate model evaluation. We also caution against comparing the performance of different ML models across different versions of your test data; performance comparions between models should be based on the same test data.\n",
    "4. Cross-validate a new copy of your ML model on your training data, and then use it with cleanlab to detect issues in the **training** dataset. Do not include test data in any part of this step to avoid leaking test set information into the training data curation.\n",
    "5. You can try **automated techniques** to curate your training data based on cleanlab results, train models on the curated training data, and evaluate them on the cleaned test data.\n",
    "\n",
    "Consider this tutorial as a blueprint for using cleanlab in diverse ML projects spanning various data modalities. The same ideas apply if you substitute *test* data with *validation* data above. In a final advanced section of this tutorial, we show how training data edits can be parameterized in terms of cleanlab's detected issues, such that hyperparameter optimization can identify the optimal combination of data edits for training an effective ML model.\n",
    "\n",
    "**Note**: This tutorial trains an XGBoost model on a tabular dataset, but the same approach applies to *any* ML model and data modality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72907260",
   "metadata": {},
   "source": [
    "## 1. Install required dependencies\n",
    "\n",
    "`Datalab` has additional dependencies that are not included in the standard installation of cleanlab.\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install xgboost\n",
    "!pip install \"cleanlab[datalab]\"\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e730c21",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "dependencies = [\"cleanlab\", \"xgboost\", \"datasets\"]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    dependencies_test = [dependency.split('>')[0] if '>' in dependency \n",
    "                         else dependency.split('<')[0] if '<' in dependency \n",
    "                         else dependency.split('=')[0] for dependency in dependencies]\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies_test:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bbf715-47c6-44ea-b15e-89800e62ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import cleanlab\n",
    "from cleanlab import Datalab\n",
    "\n",
    "SEED = 123456  # for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bbadc-547a-4bb0-8bcf-033c6890ce5e",
   "metadata": {},
   "source": [
    "### Load the data \n",
    "\n",
    "This tutorial considers a classification task with structured/tabular data. The goal is to predict each student's final grade in a course based on various numeric/categorical features about them (exam scores and notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58f8015-d051-411c-9e03-5659cf3ad956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>018bff</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>076d92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c80059</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e38f8a</td>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d57e1a</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stud_ID  exam_1  exam_2  exam_3                         notes  \\\n",
       "0  018bff    94.0    41.0    91.0       great participation +10   \n",
       "1  076d92     0.0    79.0    65.0    cheated on exam, gets 0pts   \n",
       "2  c80059    86.0    89.0    85.0  great final presentation +10   \n",
       "3  e38f8a    50.0    67.0    94.0  great final presentation +10   \n",
       "4  d57e1a    92.0    79.0    98.0  great final presentation +10   \n",
       "\n",
       "  noisy_letter_grade  \n",
       "0                  B  \n",
       "1                  F  \n",
       "2                  F  \n",
       "3                  B  \n",
       "4                  A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/clos_train_data.csv\"\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/clos_test_data.csv\"\n",
    ")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ca8e2-71a9-4699-80b3-352c325ae8e3",
   "metadata": {},
   "source": [
    "## 2. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd525-7a09-4d8e-811e-44ac1072f438",
   "metadata": {},
   "source": [
    "Before training a ML model, we preprocess our dataset. The type of preprocessing that is best will depend on what ML model you use. This tutorial will demonstrate an XGBoost model, so we'll process the **notes** and **noisy_letter_grade** columns into categorical columns for this model (each category encoded as an integer). You can alternatively use [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/), which will automatically produce a high-accuracy ML model for your raw data, without you having to worry about any ML modeling or data preprocessing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5f50e6-d125-4e61-b63e-4004f0c9099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoders for the categorical columns\n",
    "grade_le = preprocessing.LabelEncoder()\n",
    "notes_le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Process the feature columns\n",
    "train_features = df_train.drop([\"stud_ID\", \"noisy_letter_grade\"], axis=1).copy()\n",
    "train_features[\"notes\"] = notes_le.fit_transform(train_features[\"notes\"])\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "# Process the label column\n",
    "train_labels = pd.DataFrame(grade_le.fit_transform(df_train[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])\n",
    "\n",
    "\n",
    "# Keep separate copies of these training features and labels for later use\n",
    "train_features_v2 = train_features.copy()\n",
    "train_labels_v2 = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cd820-7565-4314-9dda-808cbe7c638f",
   "metadata": {},
   "source": [
    "We first solely preprocessed the training data to avoid information leakage (using test data information that would not be available at prediction time). Here's how the preprocessed training features look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36c21e9-1c32-4df9-bd87-fffeb8c2175f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_1  exam_2  exam_3 notes\n",
       "0    94.0    41.0    91.0     2\n",
       "1     0.0    79.0    65.0     0\n",
       "2    86.0    89.0    85.0     1\n",
       "3    50.0    67.0    94.0     1\n",
       "4    92.0    79.0    98.0     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da7bf-07b6-4a49-b7be-994713688bda",
   "metadata": {},
   "source": [
    "Next we apply the same preprocessing to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f856a3a-8aae-4836-b146-9ab68d8d1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = df_test.drop(\n",
    "    [\"stud_ID\", \"noisy_letter_grade\"], axis=1\n",
    ").copy()\n",
    "test_features[\"notes\"] = notes_le.transform(test_features[\"notes\"])\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "test_labels = pd.DataFrame(grade_le.transform(df_test[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da7bf-07b6-4a49-b7be-994713688bdd",
   "metadata": {},
   "source": [
    "We then appropriately format the datasets for the ML model we'll use in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46275634-da56-4e58-9061-8108be2b585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype('object')\n",
    "test_labels = test_labels.astype('object')\n",
    "\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(int)\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(int)\n",
    "\n",
    "preprocessed_train_data = pd.concat([train_features, train_labels], axis=1)\n",
    "preprocessed_train_data[\"stud_ID\"] = df_train[\"stud_ID\"]\n",
    "\n",
    "preprocessed_test_data = pd.concat([test_features, test_labels], axis=1)\n",
    "preprocessed_test_data[\"stud_ID\"] = df_test[\"stud_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2d8d0-c5ac-4e46-9ab0-aee52adaae0d",
   "metadata": {},
   "source": [
    "### Audit the merged training + test dataset with Datalab\n",
    "\n",
    "Before training any ML model, we can quickly check for fundamental issues in our setup with cleanlab. To audit all of our data at once, we merge the training and test sets into one dataset, from which we construct a `Datalab` object. `Datalab` automatically detects many types of common issues in a dataset, but requires a trained ML model for a comprehensive audit. We haven't trained any model yet, so here we instruct `Datalab` to only check for specific data issues: near duplicates, and whether the data appears non-IID (violations of the IID assumption include: data drift or lack of statistical independence between data points).\n",
    "\n",
    "`Datalab` can detect many additional types of data issues, depending on what inputs it is given. Below we provide `features = features_df` as the sole input to `Datalab.find_issues()`, which solely contains numerical values here. If you have heterogenoues/complex data types (eg. text or images), you could instead provide vector feature representations (eg. pretrained model embeddings) of your data as the `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769c4c5e-a7ff-4e02-bee5-2b2e676aec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([preprocessed_train_data, preprocessed_test_data], axis=0).reset_index(drop=True)\n",
    "features_df = full_df.drop([\"noisy_letter_grade\", \"stud_ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac47c3d-9e87-45b7-9064-bfa45578872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "\n",
      "Audit complete. 100 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "    issue_type    score  num_issues\n",
      "near_duplicate 0.583746         100\n",
      "       non_iid 0.291382           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 749, num_classes: 5\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 100\n",
      "Overall dataset quality in terms of this issue: 0.5837\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score                       near_duplicate_sets  distance_to_nearest_neighbor\n",
      "404                     True                   0.0                                     [336]                           0.0\n",
      "613                     True                   0.0  [607, 612, 611, 610, 609, 608, 606, 614]                           0.0\n",
      "614                     True                   0.0  [607, 612, 611, 610, 609, 608, 606, 613]                           0.0\n",
      "610                     True                   0.0  [607, 612, 611, 609, 608, 606, 613, 614]                           0.0\n",
      "609                     True                   0.0  [607, 612, 611, 610, 608, 606, 613, 614]                           0.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.2914\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "611             False       0.687869\n",
      "610             False       0.687883\n",
      "612             False       0.688146\n",
      "609             False       0.688189\n",
      "613             False       0.688713\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.2913818469137725\n"
     ]
    }
   ],
   "source": [
    "lab = Datalab(data=full_df, label_name=\"noisy_letter_grade\", task=\"classification\")\n",
    "lab.find_issues(features=features_df.to_numpy(), issue_types={\"near_duplicate\": {}, \"non_iid\": {}})\n",
    "lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d46ce6-29e7-4aa5-9e27-37e9e3c7107a",
   "metadata": {},
   "source": [
    "cleanlab does not find significant evidence that our data is non [IID](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables), which is good. Otherwise, we'd need to further consider where our data came from and whether conclusions/predictions from this dataset can really generalize to our population of interest.\n",
    "\n",
    "But cleanlab did detect many near duplicates in the dataset. Looking closer at these, we see some exact duplicates between our training and test data which may indicate data leakage!  Since we didn't expect these duplicates in our dataset, let's drop the extra duplicated copies of test data points found in our training set from this training set. This helps ensure that our model evaluations reflect generalization capabilities.\n",
    "Here's how we can review the near duplicates detected via `DataLab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cef169e-d15b-4d18-9cb7-8ea589557e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[336]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[607, 612, 611, 610, 609, 608, 606, 614]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[607, 612, 611, 610, 609, 608, 606, 613]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[607, 612, 611, 609, 608, 606, 613, 614]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[607, 612, 611, 610, 608, 606, 613, 614]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score  \\\n",
       "404                     True                   0.0   \n",
       "613                     True                   0.0   \n",
       "614                     True                   0.0   \n",
       "610                     True                   0.0   \n",
       "609                     True                   0.0   \n",
       "\n",
       "                          near_duplicate_sets  distance_to_nearest_neighbor  \n",
       "404                                     [336]                           0.0  \n",
       "613  [607, 612, 611, 610, 609, 608, 606, 614]                           0.0  \n",
       "614  [607, 612, 611, 610, 609, 608, 606, 613]                           0.0  \n",
       "610  [607, 612, 611, 609, 608, 606, 613, 614]                           0.0  \n",
       "609  [607, 612, 611, 610, 608, 606, 613, 614]                           0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "full_duplicate_results.sort_values(\"near_duplicate_score\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6120df47-b401-4178-9b1a-cb78250148c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training index cutoff and find the exact duplicate indices to reference\n",
    "train_idx_cutoff = len(preprocessed_train_data) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61a80f6-1d00-4a45-9355-b1ea66c6c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper column to check if any value in the list is greater than training idx cutoff\n",
    "full_duplicate_results['nd_set_has_index_over_training_cutoff'] = full_duplicate_results['near_duplicate_sets'].apply(lambda x: any(i > train_idx_cutoff for i in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900691f-ee72-43e5-b0c5-90fa0a703594",
   "metadata": {},
   "source": [
    "To distinguish between near vs. exact duplicates, we can consider the `distance_to_nearest_neighbor`. We filter for where this column has value = 0 to identify all of the exactly duplicated data points in the dataset.\n",
    "\n",
    "We also filter to check for exact duplicates between our training and test set to drop data points in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b68e0418-86cf-431f-9107-2dd0a310ca42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "      <th>nd_set_has_index_over_training_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[690, 444]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[719]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[620]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[704]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[688]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[672]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[647]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "65                      True                   0.0          [690, 444]   \n",
       "71                      True                   0.0               [719]   \n",
       "292                     True                   0.0               [620]   \n",
       "420                     True                   0.0               [704]   \n",
       "431                     True                   0.0               [688]   \n",
       "459                     True                   0.0               [672]   \n",
       "547                     True                   0.0               [647]   \n",
       "\n",
       "     distance_to_nearest_neighbor  nd_set_has_index_over_training_cutoff  \n",
       "65                            0.0                                   True  \n",
       "71                            0.0                                   True  \n",
       "292                           0.0                                   True  \n",
       "420                           0.0                                   True  \n",
       "431                           0.0                                   True  \n",
       "459                           0.0                                   True  \n",
       "547                           0.0                                   True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_duplicates = full_duplicate_results.query('is_near_duplicate_issue == True and near_duplicate_score == 0.0 and nd_set_has_index_over_training_cutoff == True').sort_values(\"near_duplicate_score\")\n",
    "exact_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74127c1e-c8e4-48ea-aa84-c4e5f15b54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_duplicates_indices = exact_duplicates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e9bd131-429f-48af-b4fc-ed8b907950b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([65, 71, 292, 420, 431, 459, 547], dtype='int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_duplicates_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b10842-0ad2-4441-a8a4-a424d9c14557",
   "metadata": {},
   "source": [
    "To remove the exact duplicates that occur between our training and test sets from our training data, let's define the last index of data points in our training set. Then we'll drop rows from our training data that correspond to all indices less than or equal to our cutoff index that are also found in the set of exact duplicates flagged by `Datalab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a959aabd-5bbd-4144-ac98-d17dda885818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the indices to drop by which indices in exact duplicates are <= to the index cutoff\n",
    "indices_of_duplicates_to_drop = [idx for idx in exact_duplicates_indices if idx <= train_idx_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72320ec-7792-4347-b2fb-630f2519127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65, 71, 292, 420, 431, 459, 547]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_of_duplicates_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f56824-c706-4448-9581-a07ea0cd9041",
   "metadata": {},
   "source": [
    "Here are the examples we'll drop from our training data, since they are exact duplicates of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8520ba4a-3ad6-408a-b377-3f47c32d745a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "      <th>stud_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>93.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ddd0ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8e6d24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>61e807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>99.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>71d7b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>90.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83e31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>70.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>edeb53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>68.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>cd52b5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes noisy_letter_grade stud_ID\n",
       "65     93.0    73.0    82.0      5                  1  ddd0ba\n",
       "71     90.0    95.0    75.0      1                  0  8e6d24\n",
       "292    79.0    62.0    82.0      5                  2  61e807\n",
       "420    99.0    53.0    76.0      5                  2  71d7b9\n",
       "431    90.0    92.0    88.0      2                  0  83e31f\n",
       "459    70.0    63.0    95.0      2                  1  edeb53\n",
       "547    68.0    93.0    73.0      5                  2  cd52b5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[indices_of_duplicates_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c002665-c48b-4f04-91f7-ad112a49efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553d5b2-1ba9-4dca-8110-eda6a8e11281",
   "metadata": {},
   "source": [
    "## 3. Train model with original (noisy) training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36319f39-f563-4f63-913f-821373180350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels[\"noisy_letter_grade\"]\n",
    "clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True, random_state=SEED)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944efa9e-dec4-474f-8007-73587453f8a6",
   "metadata": {},
   "source": [
    "**In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.**\n",
    "\n",
    "Although curating clean test data does not directly help train a better ML model, more reliable model evaluation can improve our overall ML project. For instance, clean test data can enable better informed decisions regarding when to deploy a model and better model/hyperparameter selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214e30b-4c82-4295-a3b0-68493904836b",
   "metadata": {},
   "source": [
    "## 4. Compute out-of-sample predicted probabilities for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "044c0eb1-299a-4851-b1bf-268d5bce56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "test_labels = test_labels[\"noisy_letter_grade\"].astype(int)\n",
    "\n",
    "num_crossval_folds = 5\n",
    "test_pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e3406-845a-42ff-87d5-a104837234c4",
   "metadata": {},
   "source": [
    "## 5. Use Datalab to find label issues in test data and then manually correct them\n",
    "Based on the given labels and predicted probabilities, cleanlab can quickly help us identify suspicious values in our grades table.\n",
    "\n",
    "We use cleanlab’s Datalab class which has several ways of loading the data. In this case, we’ll simply wrap the dataset (features and noisy labels) in a dictionary that is used instantiate a Datalab object such that it can audit our dataset for various types of issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c43df278-abfe-40e5-9d48-2df3efea9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 38 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "           issue_type    score  num_issues\n",
      "                label 0.649254          33\n",
      "              outlier 0.370259           5\n",
      "                 null 1.000000           0\n",
      "       near_duplicate 0.625352           0\n",
      "              non_iid 0.524042           0\n",
      "      class_imbalance 0.097015           0\n",
      "underperforming_group 1.000000           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 134, num_classes: 5\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 33\n",
      "Overall dataset quality in terms of this issue: 0.6493\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score  given_label  predicted_label\n",
      "78             True     0.000104            0                2\n",
      "109            True     0.000220            3                1\n",
      "79            False     0.000788            4                2\n",
      "106            True     0.000971            4                0\n",
      "90            False     0.001632            4                2\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 5\n",
      "Overall dataset quality in terms of this issue: 0.3703\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_outlier_issue  outlier_score\n",
      "63              True   4.752463e-99\n",
      "89              True   3.784418e-09\n",
      "40              True   5.477741e-06\n",
      "57              True   1.134230e-05\n",
      "32              True   7.153555e-03\n",
      "\n",
      "\n",
      "----------------------- null issues ------------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).\n",
      "        \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_null_issue  null_score\n",
      "0           False         1.0\n",
      "97          False         1.0\n",
      "96          False         1.0\n",
      "95          False         1.0\n",
      "94          False         1.0\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.6254\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "43                    False              0.143272                  []                      0.000016\n",
      "93                    False              0.143272                  []                      0.000016\n",
      "20                    False              0.146501                  []                      0.000016\n",
      "83                    False              0.146501                  []                      0.000016\n",
      "75                    False              0.161431                  []                      0.000018\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.5240\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "12              False       0.765240\n",
      "35              False       0.771221\n",
      "28              False       0.801589\n",
      "7               False       0.801652\n",
      "112             False       0.810735\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.5240417899434825\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.0970\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_class_imbalance_issue  class_imbalance_score  given_label\n",
      "88                     False               0.097015            4\n",
      "70                     False               0.097015            4\n",
      "2                      False               0.097015            4\n",
      "71                     False               0.097015            4\n",
      "46                     False               0.097015            4\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: NA\n",
      "\n",
      "\n",
      "--------------- underperforming_group issues ---------------\n",
      "\n",
      "About this issue:\n",
      "\tAn underperforming group refers to a collection of “hard” examples\n",
      "    for which the model predictions are poor. The quality of predictions is\n",
      "    computed using the :py:func:`get_self_confidence_for_each_label <cleanlab.rank.get_self_confidence_for_each_label>` function.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_underperforming_group_issue  underperforming_group_score\n",
      "0                            False                          1.0\n",
      "97                           False                          1.0\n",
      "96                           False                          1.0\n",
      "95                           False                          1.0\n",
      "94                           False                          1.0\n"
     ]
    }
   ],
   "source": [
    "test_data = {\"X\": test_features.values, \"y\": test_labels}\n",
    "\n",
    "test_lab = Datalab(data=test_data, label_name=\"y\", task=\"classification\") \n",
    "test_lab.find_issues(features=test_features.to_numpy(), pred_probs=test_pred_probs)\n",
    "test_lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c82c6-43df-4b4a-b8ad-0d5884ab068a",
   "metadata": {},
   "source": [
    "`cleanlab` generated a report above that illustrates many label issues in the data. We can see which examples are estimated to be mislabeled (as well as a numeric quality score quantifying how likely their label is correct) via the `get_issues` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77c7f776-54b3-45b5-9207-715d6d2e90c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0.023888</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.975067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.868448</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.078772</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_label_issue  label_score  given_label  predicted_label\n",
       "0            True     0.023888            2                4\n",
       "1           False     0.975067            1                1\n",
       "2           False     0.002811            4                1\n",
       "3           False     0.868448            3                3\n",
       "4            True     0.078772            1                3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_issue_results = test_lab.get_issues(\"label\")\n",
    "test_label_issue_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c52c4191-651a-423a-af79-50fdb1ba7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_issues = test_label_issue_results[test_label_issue_results[\"is_label_issue\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa7728-9499-4125-9f64-5f9b9e1c28e3",
   "metadata": {},
   "source": [
    "To review the most severe label issues, sort the DataFrame above by the `label_score` column (a lower score represents that the label is less likely to be correct).\n",
    "\n",
    "Let’s review some of the most likely label errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82b40638-b582-4b2c-93e3-e42e2e1d11dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>86.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>99.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>91.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes  given_label  predicted_label  label_score\n",
       "78     87.0    74.0    86.0      4            0                2     0.000104\n",
       "109    86.0    85.0    89.0      5            3                1     0.000220\n",
       "106    90.0   100.0    89.0      2            4                0     0.000971\n",
       "89     99.0    53.0    76.0      5            2                1     0.003227\n",
       "36     91.0    92.0    70.0      5            3                1     0.003788"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sorted_label_issues = test_label_issues.sort_values(\"label_score\").index\n",
    "\n",
    "test_features.iloc[test_sorted_label_issues].assign(\n",
    "    given_label=test_labels[test_sorted_label_issues],\n",
    "    predicted_label=test_label_issue_results[\"predicted_label\"].iloc[test_sorted_label_issues],\n",
    "    label_score=test_label_issues[\"label_score\"]\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e01d13-482e-46b8-a152-f37497150a91",
   "metadata": {},
   "source": [
    "The dataframe above shows the original label (`given_label`) for examples that cleanlab finds most likely to be mislabeled, as well as an alternative `predicted_label` for each example.\n",
    "\n",
    "These examples have been labeled incorrectly and should be carefully re-examined by inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d7d5ee2-2606-44e5-bcd5-1524b1ff4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_issues_to_fix = test_features.iloc[test_sorted_label_issues].assign(\n",
    "    given_label=test_labels.iloc[test_sorted_label_issues],\n",
    "    predicted_label=test_label_issue_results[\"predicted_label\"].iloc[test_sorted_label_issues],\n",
    "    label_score=test_label_issues[\"label_score\"]\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303f604e-57b5-44b7-9a32-8137957c9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_drop_from_test_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f91db0d-df14-452c-b8ed-b78728a7fe81",
   "metadata": {},
   "source": [
    "`cleanlab` found the label issues below in our test data, so let's inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee9117a-d77d-40e1-af75-2c744d484e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>86.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>99.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>91.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>87.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>92.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.019285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>64.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>95.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>69.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>72.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.058793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.061784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.097129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.102713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>93.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>93.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>59.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.170884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.380778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes  given_label  predicted_label  label_score\n",
       "78     87.0    74.0    86.0      4            0                2     0.000104\n",
       "109    86.0    85.0    89.0      5            3                1     0.000220\n",
       "106    90.0   100.0    89.0      2            4                0     0.000971\n",
       "89     99.0    53.0    76.0      5            2                1     0.003227\n",
       "36     91.0    92.0    70.0      5            3                1     0.003788\n",
       "63     91.0     0.0    94.0      0            3                0     0.006146\n",
       "123    87.0    80.0    65.0      1            1                3     0.006701\n",
       "22     99.0    86.0    95.0      3            1                0     0.007774\n",
       "52     92.0    99.0    87.0      4            1                0     0.015764\n",
       "45     95.0    88.0    69.0      5            3                4     0.016679\n",
       "61     90.0    88.0    84.0      4            2                4     0.019285\n",
       "76     64.0    73.0    79.0      1            1                3     0.021193\n",
       "0      80.0    96.0    83.0      4            2                4     0.023888\n",
       "92     95.0    87.0    82.0      3            0                2     0.025910\n",
       "74     69.0    85.0    79.0      5            2                3     0.027257\n",
       "35     94.0    97.0    91.0      5            0                1     0.039786\n",
       "133    87.0    74.0    95.0      3            2                0     0.040697\n",
       "105    72.0    80.0    69.0      5            2                3     0.041605\n",
       "124    67.0    87.0    95.0      4            2                3     0.051601\n",
       "114    74.0    88.0    97.0      5            1                4     0.058793\n",
       "12     83.0    92.0    80.0      3            2                4     0.061784\n",
       "55     79.0    73.0    78.0      5            2                1     0.071612\n",
       "4      68.0    82.0    97.0      5            1                3     0.078772\n",
       "21     83.0    80.0    86.0      5            1                4     0.085080\n",
       "16     86.0    97.0    95.0      5            0                1     0.085885\n",
       "15     72.0    69.0    81.0      4            3                2     0.097129\n",
       "67     93.0    88.0    79.0      4            2                4     0.102713\n",
       "18     93.0    68.0    86.0      4            2                0     0.114074\n",
       "120    97.0    97.0    92.0      4            1                0     0.133397\n",
       "65     93.0    82.0    85.0      4            2                4     0.150749\n",
       "129    59.0    84.0    83.0      3            3                2     0.170884\n",
       "98     95.0    81.0    76.0      5            1                3     0.380778\n",
       "9      83.0    79.0    92.0      4            2                4     0.394822"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_issues_to_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c4c6c-ce5b-4863-9675-471ff7596229",
   "metadata": {},
   "source": [
    "After manually inspecting our label issues above, we can add the indices for the label issues we want to remove from our data to our list we defined previously. \n",
    "\n",
    "Remember to **ALWAYS** inspect and manually handle label issues in your test data and to **NEVER** handle them automatically. \n",
    "\n",
    "Below, we add each of our label issues in our test data to a list of indices we will drop to clean our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e218d04-0729-4f42-b264-51c73601ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_drop_from_test_data += list(test_label_issues_to_fix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2bdb41-321e-4929-aa01-1f60948b9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)\n",
    "test_labels = test_labels.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9aba3f-1413-4a04-a74d-eb2febaf6763",
   "metadata": {},
   "source": [
    "### Evaluate classification model with original (noisy) training data on clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce2d89f-e832-448d-bfac-9941da15c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to noisy training data, measured on clean test data: 75.2%\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_features)\n",
    "acc_original = accuracy_score(test_labels, preds)\n",
    "print(\n",
    "    f\"Accuracy of model fit to noisy training data, measured on clean test data: {round(acc_original*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f5e46-8985-4a7c-bc6f-9f7be509b787",
   "metadata": {},
   "source": [
    "## 6. Compute out-of-sample predicted probabilities for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f437756-112e-4531-84fc-6ceadd0c9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crossval_folds = 5\n",
    "pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323134e9-8339-4847-9a1d-455ca0a6f449",
   "metadata": {},
   "source": [
    "## 7. Use Datalab to find label issues in training data and then manually correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e9ed45b-67b1-4531-8d8a-93439caa7eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 309 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "           issue_type    score  num_issues\n",
      "                label 0.758224         164\n",
      "              outlier 0.346721          76\n",
      "       near_duplicate 0.586934          69\n",
      "                 null 1.000000           0\n",
      "              non_iid 0.536351           0\n",
      "      class_imbalance 0.144737           0\n",
      "underperforming_group 0.979964           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 608, num_classes: 5\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 164\n",
      "Overall dataset quality in terms of this issue: 0.7582\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score  given_label  predicted_label\n",
      "352            True     0.000126            1                3\n",
      "166            True     0.000204            4                0\n",
      "216            True     0.000296            0                4\n",
      "236            True     0.000428            4                1\n",
      "182            True     0.000648            4                0\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 76\n",
      "Overall dataset quality in terms of this issue: 0.3467\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_outlier_issue  outlier_score\n",
      "593              True   1.284753e-46\n",
      "340              True   1.550359e-36\n",
      "273              True   2.164768e-28\n",
      "325              True   4.048445e-22\n",
      "315              True   1.085279e-17\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 69\n",
      "Overall dataset quality in terms of this issue: 0.5869\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score                       near_duplicate_sets  distance_to_nearest_neighbor\n",
      "607                     True                   0.0  [604, 601, 599, 602, 600, 603, 606, 605]                           0.0\n",
      "600                     True                   0.0  [604, 601, 599, 602, 607, 603, 606, 605]                           0.0\n",
      "601                     True                   0.0  [604, 599, 602, 607, 600, 603, 606, 605]                           0.0\n",
      "504                     True                   0.0                                     [225]                           0.0\n",
      "401                     True                   0.0                                 [333, 88]                           0.0\n",
      "\n",
      "\n",
      "----------------------- null issues ------------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).\n",
      "        \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_null_issue  null_score\n",
      "0            False         1.0\n",
      "401          False         1.0\n",
      "402          False         1.0\n",
      "403          False         1.0\n",
      "404          False         1.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.5364\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "169             False       0.550247\n",
      "605             False       0.627130\n",
      "606             False       0.627268\n",
      "604             False       0.627273\n",
      "607             False       0.627686\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.5363511306067167\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.1447\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_class_imbalance_issue  class_imbalance_score  given_label\n",
      "303                     False               0.144737            4\n",
      "140                     False               0.144737            4\n",
      "143                     False               0.144737            4\n",
      "484                     False               0.144737            4\n",
      "483                     False               0.144737            4\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: NA\n",
      "\n",
      "\n",
      "--------------- underperforming_group issues ---------------\n",
      "\n",
      "About this issue:\n",
      "\tAn underperforming group refers to a collection of “hard” examples\n",
      "    for which the model predictions are poor. The quality of predictions is\n",
      "    computed using the :py:func:`get_self_confidence_for_each_label <cleanlab.rank.get_self_confidence_for_each_label>` function.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.9800\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_underperforming_group_issue  underperforming_group_score\n",
      "0                             False                          1.0\n",
      "401                           False                          1.0\n",
      "402                           False                          1.0\n",
      "403                           False                          1.0\n",
      "404                           False                          1.0\n"
     ]
    }
   ],
   "source": [
    "train_data = {\"X\": train_features.values, \"y\": train_labels}\n",
    "\n",
    "train_lab = Datalab(data=train_data, label_name=\"y\", task=\"classification\")\n",
    "train_lab.find_issues(features=train_features.to_numpy(), pred_probs=pred_probs)\n",
    "train_lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25afe46c-a521-483c-b168-728c76d970dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  2,   7,  12,  23,  25,  29,  32,  34,  35,  36,\n",
       "       ...\n",
       "       571, 576, 577, 579, 581, 583, 584, 590, 592, 595],\n",
       "      dtype='int64', length=164)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issue_results = train_lab.get_issues(\"label\")\n",
    "label_issues_idx = label_issue_results[label_issue_results[\"is_label_issue\"] == True].index\n",
    "label_issues_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6efcf06f-cc40-4964-87df-5204d3b1b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates = train_lab.get_issues(\"near_duplicate\")\n",
    "near_duplicates_idx = near_duplicates[near_duplicates[\"is_near_duplicate_issue\"] == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bc87d72-bbd5-4ed2-bc38-2218862ddfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  0,   1,   3,   7,  23,  26,  47,  54,  79,  92, 103, 105, 135, 136,\n",
       "       147, 150, 157, 159, 163, 167, 197, 198, 199, 203, 212, 216, 244, 245,\n",
       "       246, 251, 260, 273, 291, 292, 299, 303, 311, 315, 317, 325, 334, 340,\n",
       "       341, 344, 354, 365, 382, 383, 392, 396, 423, 436, 448, 480, 483, 488,\n",
       "       489, 491, 493, 496, 508, 514, 515, 526, 527, 539, 547, 550, 551, 572,\n",
       "       576, 583, 584, 590, 593, 596],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = train_lab.get_issues(\"outlier\")\n",
    "outliers_idx = outliers[outliers[\"is_outlier_issue\"] == True].index\n",
    "outliers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c70be3e-0ba2-4e3e-8c50-359d402ca1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_drop = list(set(list(label_issues_idx) + list(near_duplicates_idx) + list(outliers_idx)))\n",
    "len(idx_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08080458-0cd7-447d-80e6-384cb8d31eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(idx_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(idx_to_drop, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8560d6-70e3-4cee-944e-49f047b9fff4",
   "metadata": {},
   "source": [
    "### Train model on clean training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "009bb215-4d26-47da-a230-d0ccf4122629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True, random_state=SEED)\n",
    "clean_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe23e39-fe7b-4145-af55-c7fc1f245850",
   "metadata": {},
   "source": [
    "**In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f83f8-07e6-4702-a39e-94336268bfef",
   "metadata": {},
   "source": [
    "### Evaluate classification model with clean training on clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcaeda51-9b24-4c04-889d-7e63563594fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to clean training data, measured on clean test data: 77.2%\n"
     ]
    }
   ],
   "source": [
    "clean_preds = clean_clf.predict(test_features)\n",
    "acc_clean = accuracy_score(test_labels, clean_preds)\n",
    "print(\n",
    "    f\"Accuracy of model fit to clean training data, measured on clean test data: {round(acc_clean*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2624388-ad39-4c88-88c3-51a224ad549a",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Optimization for editing data issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8e3fe-b15f-41e0-87dd-0efb786f2920",
   "metadata": {},
   "source": [
    "We have made some basic edits to improve test performance, so now we will parameterize each one of these edits (eg. what fraction of each issue to delete) to automatically find the best combination of edits to achieve optimal test performance. \n",
    "\n",
    "We will use a basic hyperparameter-tuning approach to optimize over these edit-variants + model re-training on the edited datasets with our objective being test performance.\n",
    "\n",
    "In a real-world setting, this would ideally be done on cleaned validation data instead of test data, but we are simplifying the approach for this tutorial.\n",
    "\n",
    "To parametrize our dataset edits, we define a `dict` below containing default settings that we found tend to work well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d92d78d-e4a8-4322-bf38-f5a5dae3bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_edit_params = {\n",
    "        \"drop_label_issue\": 0.5,\n",
    "        \"drop_near_duplicate\": 0.2,\n",
    "        \"drop_outlier\": 0.5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcc027-7e51-4583-ab6d-9fc73f847c90",
   "metadata": {},
   "source": [
    "In english, these choices mean:\n",
    "\n",
    "- `drop_label_issue`: We drop the remaining top 50% of the datapoints flagged with label issues (based on label score). Here we do not drop any of the relabeled datapoints from the prior step.\n",
    "- `drop_outlier`: We drop the top 50% most severe outliers based on outlier score (amongst the set of flagged outliers).\n",
    "- `drop_near_duplicate`: We drop EXTRA COPIES of the top 20% of near duplicates (based on near duplicate score). Never drop the original datapoint though, so at least one copy remains. How do we decide on the original datapoint? Amongst each set of near duplicates, we keep the one that has highest self-confidence score for its given label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b144-f0d1-49a6-a0f7-852fdb2bd71c",
   "metadata": {},
   "source": [
    "`cleanlab`'s `DataLab` object helps us define, in sorted (ascending) order based on the severity of issue score, our issues below. We will use in our hyperparameter optimization to find what combination of datapoints we drop improves our ML model results the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0541a89d-6794-449a-a880-b52e963d14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues = train_lab.get_issues(\"label\").query(\"is_label_issue\").sort_values(\"label_score\")\n",
    "near_duplicates = train_lab.get_issues(\"near_duplicate\").query(\"is_near_duplicate_issue\").sort_values(\"near_duplicate_score\")\n",
    "outliers = train_lab.get_issues(\"outlier\").query(\"is_outlier_issue\").sort_values(\"outlier_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c75d9d2-ea32-4e55-8b57-7f9ad73810d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_features, train_labels, label_issues, near_duplicates, outliers, drop_label_issue, drop_near_duplicate, drop_outlier):\n",
    "    \"\"\"\n",
    "    Preprocesses the training data by dropping a specified percentage of data points identified as label issues,\n",
    "    near duplicates, and outliers based on the full datasets provided for each issue type.\n",
    "    \n",
    "    Args:\n",
    "        train_features (pd.DataFrame): DataFrame containing the training features.\n",
    "        train_labels (pd.Series): Series containing the training labels.\n",
    "        label_issues (pd.DataFrame): DataFrame containing data points with label issues.\n",
    "        near_duplicates (pd.DataFrame): DataFrame containing data points identified as near duplicates.\n",
    "        outliers (pd.DataFrame): DataFrame containing data points identified as outliers.\n",
    "        drop_label_issue (float): Percentage of label issue data points to drop.\n",
    "        drop_near_duplicate (float): Percentage of near duplicate data points to drop.\n",
    "        drop_outlier (float): Percentage of outlier data points to drop.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned training features.\n",
    "        pd.Series: The cleaned training labels.\n",
    "    \"\"\"\n",
    "    # Extract indices for each type of issue\n",
    "    label_issues_idx = label_issues.index.tolist()\n",
    "    near_duplicates_idx = near_duplicates.index.tolist()\n",
    "    outliers_idx = outliers.index.tolist()\n",
    "    \n",
    "    # Calculate the number of each type of data point to drop except near duplicates, which requires separate logic\n",
    "    num_label_issues_to_drop = int(len(label_issues_idx) * drop_label_issue)\n",
    "    num_outliers_to_drop = int(len(outliers_idx) * drop_outlier)\n",
    "\n",
    "    # Calculate number of near duplicates to drop\n",
    "    # Assuming the 'near_duplicate_sets' are lists of indices (integers) of near duplicates\n",
    "    clusters = []\n",
    "    for i in near_duplicates_idx:\n",
    "        # Create a set for each cluster, add the current index to its near duplicate set\n",
    "        cluster = set(near_duplicates.at[i, 'near_duplicate_sets'])\n",
    "        cluster.add(i)\n",
    "        clusters.append(cluster)\n",
    "    \n",
    "    # Deduplicate clusters by converting the list of sets to a set of frozensets\n",
    "    unique_clusters = set(frozenset(cluster) for cluster in clusters)\n",
    "    \n",
    "    # If you need the unique clusters back in list of lists format:\n",
    "    unique_clusters_list = [list(cluster) for cluster in unique_clusters]\n",
    "    \n",
    "    near_duplicates_idx_to_drop = []\n",
    "    \n",
    "    for cluster in unique_clusters_list:\n",
    "        # Calculate the number of rows to drop, ensuring at least one datapoint remains\n",
    "        n_drop = max(math.ceil(len(cluster) * drop_near_duplicate), 1)  # Drop at least k% or 1 row\n",
    "        if len(cluster) > n_drop:  # Ensure we keep at least one datapoint\n",
    "            # Randomly select datapoints to drop\n",
    "            drops = random.sample(cluster, n_drop)\n",
    "        else:\n",
    "            # If the cluster is too small, adjust the number to keep at least one datapoint\n",
    "            drops = random.sample(cluster, len(cluster) - 1)  # Keep at least one\n",
    "        near_duplicates_idx_to_drop.extend(drops)\n",
    "    \n",
    "    # Determine the specific indices to drop\n",
    "    label_issues_idx_to_drop = label_issues_idx[:num_label_issues_to_drop]\n",
    "    outliers_idx_to_drop = outliers_idx[:num_outliers_to_drop]\n",
    "    \n",
    "    # Combine the indices to drop\n",
    "    idx_to_drop = list(set(label_issues_idx_to_drop + near_duplicates_idx_to_drop + outliers_idx_to_drop))\n",
    "    \n",
    "    # Drop the rows from the training data\n",
    "    train_features_cleaned = train_features.drop(idx_to_drop).reset_index(drop=True)\n",
    "    train_labels_cleaned = train_labels.drop(idx_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return train_features_cleaned, train_labels_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5aa2883-d20d-481f-a012-fcc7ff8e3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the parameter grid as lists of possible values\n",
    "param_grid = {\n",
    "    'drop_label_issue': [0.4, 0.5, 0.6],\n",
    "    'drop_near_duplicate': [0.1, 0.2, 0.3],\n",
    "    'drop_outlier': [0.4, 0.5, 0.6],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(product(param_grid['drop_label_issue'], param_grid['drop_near_duplicate'], param_grid['drop_outlier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce1c0ada-88b1-4654-b43f-3c0b59002979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'drop_label_issue': 0.6, 'drop_near_duplicate': 0.2, 'drop_outlier': 0.5}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for drop_label_issue, drop_near_duplicate, drop_outlier in param_combinations:\n",
    "    # Preprocess the data for the current combination of parameters\n",
    "    train_features_preprocessed, train_labels_preprocessed = preprocess_data(\n",
    "        train_features_v2, train_labels_v2, label_issues, near_duplicates, outliers,\n",
    "        drop_label_issue, drop_near_duplicate, drop_outlier)\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    model = XGBClassifier(tree_method=\"hist\", enable_categorical=True, random_state=SEED)\n",
    "    model.fit(train_features_preprocessed, train_labels_preprocessed)\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    # Update the best score and parameters if the current model is better\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_params = {'drop_label_issue': drop_label_issue, 'drop_near_duplicate': drop_near_duplicate, 'drop_outlier': drop_outlier}\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f572acf-31c3-4874-9100-451796e35b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to clean training data based on the optimal combinations of hyperparameters to clean our data, measured on clean test data: 80.2%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy of model fit to clean training data based on the optimal combinations of hyperparameters to clean our data, measured on clean test data: {round(best_score*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc306eff-f3b7-4098-9f7e-3d17d1d0016a",
   "metadata": {},
   "source": [
    "`cleanlab` was able to successfully help us improve ML performance in this tutorial! We saw how `cleanlab` helped us find and manually fix different data issue types in our test data to clean it. \n",
    "\n",
    "Then we fit a model on our noisy training data but evaluated it on our clean test data. We cleaned our training data by first dropping all rows for each issue type and fit a new model on our clean training data and evaluated it on our clean test data (and saw improvement already in model accuracy)! \n",
    "\n",
    "We then were able to further improve model accuracy by optimizing for the exact amount of each issue type to drop from our data using hyperparameter optimization. \n",
    "\n",
    "To reiterate, here are the 2 main takeaways:\n",
    "  - Don’t algorithmically change test data\n",
    "  - Do NOT evaluate same model on the 2 different test sets (noisy and clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcd11987-8497-48f6-bb6f-f28f460e8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "assert(acc_clean*100 - acc_original*100 >= 1.5)\n",
    "assert(best_score*100 - acc_clean*100 >= 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mturk-env",
   "language": "python",
   "name": "mturk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
